{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load - 전처리 width, height, input_channel 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from numpy import dstack\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.io import arff, loadmat\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Multivariate Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fnames = ['ArabicDigits','CMUsubject16','ECG','JapaneseVowels','KickVsPunch', 'Libras','Outflow','UWave','Wafer','WalkVsRun']\n",
    "fnames = ['Libras','UWave']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Libras dataset\n"
     ]
    }
   ],
   "source": [
    "fname = fnames[0]\n",
    "data_path = './data/'+fname\n",
    "mat = loadmat(data_path+'/'+fname+'.mat') \n",
    "print('Load '+fname+' dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_trains: 180 \tnb_tests: 180 \tnb_classes: 15\n",
      "nb_features: 2 \tlength: 45\n"
     ]
    }
   ],
   "source": [
    "trainx = mat['mts']['train']\n",
    "trainy = mat['mts']['trainlabels']\n",
    "testx = mat['mts']['test']\n",
    "testy = mat['mts']['testlabels']\n",
    "\n",
    "nb_trains = trainx[0][0].shape[1]\n",
    "nb_tests = testx[0][0].shape[1]\n",
    "nb_classes = trainy[0][0][-1][0]\n",
    "print('nb_trains:',nb_trains,'\\tnb_tests:',nb_tests, '\\tnb_classes:', nb_classes)\n",
    "nb_features = trainx[0][0][0][0].shape[0]\n",
    "length = trainx[0][0][0][0].shape[1]\n",
    "print('nb_features:',nb_features, '\\tlength:', length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make (nb_trains, length, nb_features)\n",
    "Libras와 UWave를 제외한 나머지 데이터들은 length가 유동적이여서 현재 모델 입력에 적당하지 않음\n",
    "따라서 Libras와 UWave 데이터만 일단 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshaping(X, Y):\n",
    "    X = X[0][0][0]\n",
    "    reshapedX = []\n",
    "    for i in range(len(X)):\n",
    "        reshapedX.append(X[i])\n",
    "    reshapedX = np.array(reshapedX, dtype=np.float64)\n",
    "    X = reshapedX.reshape(reshapedX.shape[0], reshapedX.shape[2], reshapedX.shape[1])\n",
    "    \n",
    "    Y = Y[0][0]\n",
    "    reshapedY = []\n",
    "    for i in range(len(Y)):\n",
    "        reshapedY.append(Y[i][0])\n",
    "\n",
    "    reshapedY = np.array(reshapedY, dtype=np.int64)\n",
    "    trainy = reshapedY.reshape(reshapedY.shape[0], 1)\n",
    "    \n",
    "    return X, Y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx, trainy = reshaping(trainx, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx, testy = reshaping(testx, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size:16\n",
      "(180, 45, 2) (180, 1)\n",
      "(180, 45, 2) (180, 1)\n"
     ]
    }
   ],
   "source": [
    "batch_size = min(int(trainx.shape[0]/10), 16)\n",
    "print (\"batch size:{}\".format(batch_size))\n",
    "print(trainx.shape, trainy.shape)\n",
    "print(testx.shape, testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train shape: (180, 15)\n",
      "y test shape: (180, 15)\n"
     ]
    }
   ],
   "source": [
    "hot_encoded_y_train = np.asarray(pd.get_dummies(np.asarray(trainy.flatten())))\n",
    "hot_encoded_y_test = np.asarray(pd.get_dummies(np.asarray(testy.flatten())))\n",
    "print(\"y train shape: {}\".format(hot_encoded_y_train.shape))\n",
    "print(\"y test shape: {}\".format(hot_encoded_y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX shape:(180, 1, 45, 2)\n",
      "trainY shape:(180, 15)\n",
      "validX shape:(90, 1, 45, 2)\n",
      "validY shape:(90, 15)\n",
      "testX shape:(90, 1, 45, 2)\n",
      "testY shape:(90, 15)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainx[:, np.newaxis, :]\n",
    "trainY = hot_encoded_y_train\n",
    "validX =testx[:len(testx)//2,np.newaxis,:]\n",
    "validY= hot_encoded_y_test[:len(testx)//2]\n",
    "testX = testx[len(testx)//2:,np.newaxis,:]\n",
    "testY = hot_encoded_y_test[len(testx)//2:]\n",
    "print (\"trainX shape:{}\".format(trainX.shape))\n",
    "print (\"trainY shape:{}\".format(trainY.shape))\n",
    "print (\"validX shape:{}\".format(validX.shape))\n",
    "print (\"validY shape:{}\".format(validY.shape))\n",
    "print (\"testX shape:{}\".format(testX.shape))\n",
    "print (\"testY shape:{}\".format(testY.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height 1\n",
      "width 45\n",
      "input_channel 2\n"
     ]
    }
   ],
   "source": [
    "height = trainX.shape[1]\n",
    "width = trainX.shape[2]\n",
    "input_channel = trainX.shape[3]\n",
    "print (\"height {}\".format(height))\n",
    "print (\"width {}\".format(width))\n",
    "print (\"input_channel {}\".format(input_channel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FaceDetection\n",
    "Classes: Face (Class 1) or Scramble (Class 0)\n",
    "\n",
    "Dataset Link: http://www.timeseriesclassification.com/description.php?Dataset=FaceDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = arff.loadarff('./data/Multivariate_arff/FaceDetection/FaceDetection_TRAIN.arff')\n",
    "tst = arff.loadarff('./data/Multivariate_arff/FaceDetection/FaceDetection_TEST.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx, trainy  = trn[0]['SERIES'], trn[0]['class']\n",
    "testx, testy  = tst[0]['SERIES'], tst[0]['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshapingFaceDetection(X, Y):\n",
    "    reshapedX = []\n",
    "    sample = []\n",
    "    for i in range(len(X)):\n",
    "        for j in range(len(X[i])):\n",
    "            sample.append(X[i][j].tolist())\n",
    "        reshapedX.append(sample)\n",
    "        sample = []\n",
    "    reshapedX = np.array(reshapedX, dtype=np.float64)\n",
    "    \n",
    "    reshapedY = []\n",
    "    reshapedY = np.array(Y, dtype=np.int64)\n",
    "    reshapedY = reshapedY.reshape(reshapedY.shape[0],1)\n",
    "\n",
    "    return reshapedX, reshapedY    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx, trainy = reshapingFaceDetection(trainx, trainy)\n",
    "testx, testy = reshapingFaceDetection(testx, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (5890, 144, 62) (5890, 1)\n",
      "test:  (3524, 144, 62) (3524, 1)\n"
     ]
    }
   ],
   "source": [
    "print('train: ', trainx.shape, trainy.shape)\n",
    "print('test: ', testx.shape, testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size:16\n",
      "(5890, 144, 62) (5890, 1)\n",
      "(3524, 144, 62) (3524, 1)\n"
     ]
    }
   ],
   "source": [
    "batch_size = min(int(trainx.shape[0]/10), 16)\n",
    "print (\"batch size:{}\".format(batch_size))\n",
    "print(trainx.shape, trainy.shape)\n",
    "print(testx.shape, testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train shape: (5890, 2)\n",
      "y test shape: (3524, 2)\n"
     ]
    }
   ],
   "source": [
    "hot_encoded_y_train = np.asarray(pd.get_dummies(np.asarray(trainy.flatten())))\n",
    "hot_encoded_y_test = np.asarray(pd.get_dummies(np.asarray(testy.flatten())))\n",
    "print(\"y train shape: {}\".format(hot_encoded_y_train.shape))\n",
    "print(\"y test shape: {}\".format(hot_encoded_y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX shape:(5890, 1, 144, 62)\n",
      "trainY shape:(5890, 2)\n",
      "validX shape:(1762, 1, 144, 62)\n",
      "validY shape:(1762, 2)\n",
      "testX shape:(1762, 1, 144, 62)\n",
      "testY shape:(1762, 2)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainx[:, np.newaxis, :]\n",
    "trainY = hot_encoded_y_train\n",
    "validX =testx[:len(testx)//2,np.newaxis,:]\n",
    "validY= hot_encoded_y_test[:len(testx)//2]\n",
    "testX = testx[len(testx)//2:,np.newaxis,:]\n",
    "testY = hot_encoded_y_test[len(testx)//2:]\n",
    "print (\"trainX shape:{}\".format(trainX.shape))\n",
    "print (\"trainY shape:{}\".format(trainY.shape))\n",
    "print (\"validX shape:{}\".format(validX.shape))\n",
    "print (\"validY shape:{}\".format(validY.shape))\n",
    "print (\"testX shape:{}\".format(testX.shape))\n",
    "print (\"testY shape:{}\".format(testY.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height 1\n",
      "width 144\n",
      "input_channel 62\n"
     ]
    }
   ],
   "source": [
    "height = trainX.shape[1]\n",
    "width = trainX.shape[2]\n",
    "input_channel = trainX.shape[3]\n",
    "print (\"height {}\".format(height))\n",
    "print (\"width {}\".format(width))\n",
    "print (\"input_channel {}\".format(input_channel))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
